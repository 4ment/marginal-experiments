---
title: "DS[1,2,3,3s,4,5]"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: pdf_document
---

```{r setup, include=FALSE}
library(reshape2)
library(ggplot2)
library(knitr)
library(tidyr)
library(dplyr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, fig.path='Figs/')
```

- SRF: posterior distribution cacluated with golden runs
- NMC: naive Monte Carlo with 10,000 samples
- ELBO: evidence lower bound (mean field Gaussian)
- HM: harmonic mean
- SHM: stabilized harmonic mean
- SS: stepping stone with 50 power posteriors
- GSS: generalized stepping stone with 50 power posterior. Reference distribution is independent gamma distributions.
- PS: path sampling with beta(0.3,1) and 50 power posteriors
- PS2: modified path sampling with beta(0.3,1) and 50 power posteriors
- ML: maximum likleihood
- MAP: maximum a posteriori using exp(10) as prior on each branch
- BS: bridge sampling
- NS: nested sampling
- CPO: conditional predictive ordinate
- LPPD: log pointwise predictive density
- GL: gamma Laplace
- LL: lognormal Laplace
- BL: beta' Laplace
- GLIS: gamma Laplace with importance sampling (10,000 samples)
- VBIS: Importance sampling using a variational distribution as the importance distribution 10,000 samples

```{r}
log.sum.exp<- function(x) {
  # Computes log(sum(exp(x))
  # Uses offset trick to avoid numeric overflow: http://jblevins.org/notes/log-sum-exp
  if ( max(abs(x)) > max(x) )
    offset <- min(x)
  else
    offset <- max(x)
  log(sum(exp(x - offset))) + offset
}

kl.log.pq <- function(P,Q){
  sum(exp(P)*(P-Q))
}

h.log.pq <-function(P, Q){
  sqrt(sum( (sqrt(exp(P)) - sqrt(exp(Q)))^2 ))/sqrt(2)
}

calc.kl.h <- function(df, srf){
  logpp = srf - log.sum.exp(srf) # sum(exp(df$pp)) != 1 so normalize too
  df2 = data.frame(matrix(nrow=ncol(df), ncol=2))
  rownames(df2) = colnames(df)
  colnames(df2) = c('KL', 'Hellinger')
  for(i in 1:ncol(df)){
    logprob = df[,i] - log.sum.exp(df[,i])
    df2[i,] = c(kl.log.pq(logpp, logprob), h.log.pq(logpp, logprob))
  }
  df2
}

read.ds <- function(dataset){
  df = read.csv(file.path(dataset, paste(dataset, ".csv", sep="")), sep='\t')
  srf = read.csv(file.path(dataset, "data.csv"), sep='\t')
  srf = srf %>% mutate(SRF=log(SRF))

  dfff = df %>% filter(algorithm %in% c('mcmc', 'mmcmc', 'mmcmc-gss'))%>%
    spread(algorithm,time) %>% select(-marginal)
  df = filter(df, !(algorithm %in% c('mcmc', 'mmcmc', 'mmcmc-gss')))
  dfff = dfff %>% right_join(df, by='tree')
  #MMCMC
  for(m in c('SS', 'PS', 'PS2')){
    dfff[dfff$algorithm==m,]$time  = dfff[dfff$algorithm==m,]$time + 
      dfff[dfff$algorithm==m,]$mmcmc
  }
  #MCMC
  for(m in c('BS', 'CPO', 'LPPD', 'HM', 'SHM')){
    dfff[dfff$algorithm==m,]$time  = dfff[dfff$algorithm==m,]$time + 
      dfff[dfff$algorithm==m,]$mcmc
  }
  dfff[dfff$algorithm=='GSS',]$time  = dfff[dfff$algorithm=='GSS',]$time +
    dfff[dfff$algorithm=='GSS',]$`mmcmc-gss`
  
  df.time = dfff %>% group_by(algorithm) %>% 
    summarise(median=median(time),mean=mean(time), sd=sd(time), cv=sd(time)/mean(time))
  
  # KL
  dd = dfff %>% select(tree, marginal, algorithm)  %>% spread(algorithm, marginal) %>%
    full_join(srf, by='tree') %>% arrange(tree) %>% select(-tree)
  
  if(sum(complete.cases(dd)) != nrow(dd)){
    #dd = dd[complete.cases(dd),]
    dd = dd[1:1000,]
  }
  df.kl = calc.kl.h(select(dd,-SRF), select(dd,SRF))

  # plot
  df.plot = dfff %>% full_join(srf, by='tree') %>% 
    mutate(algorithm=factor(algorithm, levels=rownames(df.kl[order(df.kl$KL),])))

  list(time=df.time, kl=df.kl, plot=df.plot)
}
```

```{r}
#load("DS.RData")

DS1 = read.ds('DS1')
DS2 = read.ds('DS2')
DS3 = read.ds('DS3')
DS3s = read.ds('DS3s')
DS4 = read.ds('DS4')
DS5 = read.ds('DS5')

save(DS1, DS2, DS3, DS3s, DS4, DS5, file="DS.RData")
```

\newpage

# DS1
```{r}
df1.time = DS1[['time']]
kable(df1.time[order(df1.time$median),])
```

\newpage

```{r}
df1.kl = DS1[['kl']]
kable(df1.kl[order(df1.kl$KL),])
```

\newpage

```{r fig.height=9, fig.width=10}
df.plot = DS1[['plot']]
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```

\newpage

# DS2
```{r}
df2.time = DS2[['time']]
kable(df2.time[order(df2.time$median),])
```

\newpage

```{r}
df2.kl = DS2[['kl']]
kable(df2.kl[order(df2.kl$KL),])
```

\newpage

```{r fig.height=9, fig.width=10}
df.plot = DS2[['plot']]
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```


\newpage

# DS3
```{r}
df3.time = DS3[['time']]
kable(df3.time[order(df3.time$median),])
```

\newpage

```{r}
df3.kl = DS3[['kl']]
kable(df3.kl[order(df3.kl$KL),])
```

\newpage

```{r fig.height=9, fig.width=10}
df.plot = DS3[['plot']]
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```


\newpage

# DS3 simulated
```{r}
df.time = DS3s[['time']]
kable(df.time[order(df.time$median),])
```

\newpage

```{r}
df3s.kl = DS3s[['kl']]
kable(df3s.kl[order(df3s.kl$KL),])
```

\newpage

```{r fig.height=9, fig.width=10}
df.plot = DS3s[['plot']]
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```

\newpage

# DS4
```{r}
df4.time = DS4[['time']]
kable(df4.time[order(df4.time$median),])
```

\newpage

```{r}
df4.kl = DS4[['kl']]
kable(df4.kl[order(df4.kl$KL),])
```

\newpage

```{r fig.height=9, fig.width=10}
df.plot = DS4[['plot']]
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```

\newpage

# DS5
```{r}
df5.time = DS5[['time']]
kable(df5.time[order(df5.time$median),])
```

\newpage
## KL with 1000 trees
```{r}
df5.kl = DS5[['kl']]
kable(df5.kl[order(df5.kl$KL),])
```

\newpage

## Plot with 1,000 trees
```{r fig.height=9, fig.width=10}
df.plot = DS5[['plot']] %>% filter(tree < 1000)
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```


\newpage

## Plot with 10,000 trees (no MCMC based methods)
```{r fig.height=9, fig.width=10}
df.plot = DS5[['plot']]
nomcmc = as.vector(unique(df.plot[df.plot$tree > 1000,]$algorithm))
df.plot = df.plot %>% filter(algorithm %in% nomcmc)
ggplot(df.plot, aes(x=SRF, y=marginal)) +
  facet_wrap( ~algorithm, scales = "free_y", ncol=2) +
  geom_point()
```

\newpage

```{r eval=FALSE, echo=FALSE}
knitr::kable(list(df1.kl[order(df1.kl$KL), "KL", drop=FALSE],
                  df2.kl[order(df2.kl$KL), "KL", drop=FALSE],
                  df3.kl[order(df3.kl$KL), "KL", drop=FALSE],
                  df3s.kl[order(df3s.kl$KL), "KL", drop=FALSE],
                  df4.kl[order(df4.kl$KL), "KL", drop=FALSE]), booktabs = T)# %>% kable_styling(latex_options = c("striped", "scale_down"))
```

# Every dataset together
```{r}
knitr::kable(cbind(tibble::rownames_to_column(df1.kl[order(df1.kl$KL), "KL", drop=FALSE], 'DS1'),
                  tibble::rownames_to_column(df2.kl[order(df2.kl$KL), "KL", drop=FALSE], 'DS2'),
                  tibble::rownames_to_column(df3.kl[order(df3.kl$KL), "KL", drop=FALSE], 'DS3'),
                  tibble::rownames_to_column(df3s.kl[order(df3s.kl$KL), "KL", drop=FALSE], 'DS3s'),
                  tibble::rownames_to_column(df4.kl[order(df4.kl$KL), "KL", drop=FALSE], 'DS4'),
                  tibble::rownames_to_column(df4.kl[order(df4.kl$KL), "KL", drop=FALSE], 'DS5')),
             booktabs = T)
```

\newpage

## Method vs. KL (log scale)
```{r}
all.kl = as.data.frame(cbind(df1.kl$KL,df2.kl$KL,df3.kl$KL,df4.kl$KL,df5.kl$KL))
myorder = rowMeans(all.kl)
myorder = apply(all.kl, 1, median)
all.kl = log(all.kl)
all.kl = cbind(rownames(df1.kl), all.kl)
colnames(all.kl) = c("Method", "DS1", "DS2", "DS3", "DS4", "DS5")
all.kl2 = gather(all.kl, Dataset, KL, DS1:DS5)
all.kl2$Method = factor(all.kl2$Method, levels=rownames(df1.kl)[order(myorder,decreasing=T)])
ggplot(all.kl2, aes(x=Method)) + geom_point(aes(y=KL,col=Dataset)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

\newpage

## Method against running time (log scale)
```{r}
all.time = as.data.frame(cbind(df1.time$median, df2.time$median, df3.time$median, df4.time$median,df5.time$median))
myorder = rowMeans(all.time)
myorder = apply(all.time, 1, median)
all.time = log(all.time)
all.time = cbind(df1.time$algorithm, all.time)
colnames(all.time) = c("Method", "DS1", "DS2", "DS3", "DS4", "DS5")
all.time2 = gather(all.time, Dataset, Time, DS1:DS5)
all.time2$Method = factor(all.time2$Method, levels=all.time$Method[order(myorder,decreasing=T)])
ggplot(all.time2, aes(x=Method)) + geom_point(aes(y=Time,col=Dataset)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

\newpage

## Method against running time*KL (log scale)
```{r}
all = all.kl2 %>%  full_join(all.time2, by=c("Method", 'Dataset'))
all$ratio = all$KL+all$Time
myorder = all %>% group_by(Method) %>% summarize(avg=median(ratio)) %>% select(avg)
all$Method = factor(all$Method, levels=all$Method[order(myorder$avg,decreasing=T)])
ggplot(all, aes(x=Method)) + geom_point(aes(y=ratio,col=Dataset)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```

