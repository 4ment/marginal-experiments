---
title: "DS[1,2,3,3s,4,5]"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: pdf_document
---

```{r setup, include=FALSE}
library(reshape2)
library(ggplot2)
library(knitr)
library(tidyr)
library(dplyr)
library(kableExtra)
knitr::opts_chunk$set(echo = TRUE, fig.path='Figs/')
```

- SRF: posterior distribution cacluated with golden runs
- NMC: naive Monte Carlo with 10,000 samples
- ELBO: evidence lower bound (mean field Gaussian)
- HM: harmonic mean
- SHM: stabilized harmonic mean
- SS: stepping stone with 50 power posteriors
- GSS: generalized stepping stone with 50 power posterior. Reference distribution is independent gamma distributions.
- PS: path sampling with beta(0.3,1) and 50 power posteriors
- PS2: modified path sampling with beta(0.3,1) and 50 power posteriors
- ML: maximum likleihood
- MAP: maximum a posteriori using exp(10) as prior on each branch
- BS: bridge sampling
- NS: nested sampling
- CPO: conditional predictive ordinate
- LPPD: log pointwise predictive density
- GL: gamma Laplace
- LL: lognormal Laplace
- BL: beta' Laplace
- GLIS: gamma Laplace with importance sampling (10,000 samples)
- VBIS: Importance sampling using a variational distribution as the importance distribution 10,000 samples

```{r}
log.sum.exp<- function(x) {
  # Computes log(sum(exp(x))
  # Uses offset trick to avoid numeric overflow: http://jblevins.org/notes/log-sum-exp
  if ( max(abs(x)) > max(x) )
    offset <- min(x)
  else
    offset <- max(x)
  log(sum(exp(x - offset))) + offset
}

kl.log.pq <- function(P,Q, normalize=FALSE){
  if(normalize){
    Q = Q - log.sum.exp(Q)
    P = P - log.sum.exp(P)
  }
  sum(exp(P)*(P-Q))
}

h.log.pq <-function(P, Q, normalize=FALSE){
  if(normalize){
    Q = log.sum.exp(Q)
    P = log.sum.exp(P)
  }
  sqrt(sum( (sqrt(exp(P)) - sqrt(exp(Q)))^2 ))/sqrt(2)
}

read.ds <- function(dataset){
  df = read.csv(file.path(dataset, paste(dataset, ".csv", sep="")), sep='\t')
  srf = read.csv(file.path(dataset, "data.csv"), sep='\t')
  srf = srf %>% mutate(SRF=log(SRF))
  df = mutate(df, rep=rep+1)

  dfff = df %>% filter(algorithm %in% c('mcmc', 'mmcmc', 'mmcmc-gss'))%>%
    spread(algorithm,time) %>% select(-marginal)
  df = filter(df, !(algorithm %in% c('mcmc', 'mmcmc', 'mmcmc-gss')))
  dfff = dfff %>% right_join(df, by=c('rep','tree'))
  #MMCMC
  for(m in c('SS', 'PS', 'PS2')){
    dfff[dfff$algorithm==m,]$time  = dfff[dfff$algorithm==m,]$time + 
      dfff[dfff$algorithm==m,]$mmcmc
  }
  #MCMC
  for(m in c('BS', 'CPO', 'LPPD', 'HM', 'SHM')){
    dfff[dfff$algorithm==m,]$time  = dfff[dfff$algorithm==m,]$time + 
      dfff[dfff$algorithm==m,]$mcmc
  }
  dfff[dfff$algorithm=='GSS',]$time  = dfff[dfff$algorithm=='GSS',]$time +
    dfff[dfff$algorithm=='GSS',]$`mmcmc-gss`
  
  df.time = dfff %>% group_by(algorithm) %>% 
    summarise(median=median(time),mean=mean(time), sd=sd(time), cv=sd(time)/mean(time)) %>%
    arrange(algorithm)
  
  # KL
  df.kl = dfff %>% full_join(srf, by='tree') %>% group_by(rep, algorithm) %>%
    summarize(KL=kl.log.pq(SRF, marginal, TRUE), H=h.log.pq(SRF, marginal, TRUE)) %>%
    arrange(algorithm) %>% mutate(dataset=dataset)

  # plot
  myorder = df.kl %>% filter(rep==1) %>% arrange(KL) %>% ungroup() %>%
    select(algorithm) %>% unlist(use.names = FALSE) %>% as.vector
  
  df.plot = dfff %>% full_join(srf, by='tree') %>% 
    mutate(algorithm=factor(algorithm, levels=myorder))

  list(time=df.time, kl=df.kl, plot=df.plot, marginals=dfff)
}
```

```{r include=FALSE}
datasets = paste0('DS', 1:5)
out = NULL
for(i in 1:length(datasets)){
  out = c(out, knit_expand('DSx.Rmd'))
}
```

`r paste(knit(text = out), collapse = '\n')`

\newpage

## Method vs. KL (log scale)
```{r method-kl}
all.kl = read.ds(datasets[1])[['kl']]
for(i in 2:length(datasets)){
  kl = read.ds(datasets[i])
  all.kl = rbind(all.kl, kl[['kl']])
}

all.kl = all.kl %>% filter(rep==1) %>% select(-rep)
myorder = all.kl %>% group_by(algorithm) %>% summarize(medianKL=median(KL)) %>%
  arrange(-medianKL) %>% select(algorithm) %>% unlist(use.names = FALSE) %>% as.vector

all.kl$Method = factor(all.kl$algorithm, levels=myorder)
ggplot(all.kl, aes(x=Method)) + geom_point(aes(y=KL,col=dataset)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  scale_y_log10() 
```

\newpage

## Method against running time (log scale)
```{r method-time}
ds1 = read.ds(datasets[1])
all.time = as.data.frame(ds1[['time']]$median)
for(i in 2:length(datasets)){
  ds.time = read.ds(datasets[i])
  all.time = cbind(all.time, ds.time[['time']]$median)
}

myorder = rowMeans(all.time)
myorder = apply(all.time, 1, median)
all.time = log(all.time)
all.time = cbind(ds1[['time']]$algorithm, all.time)
colnames(all.time) = c("Method", "DS1", "DS2")#, "DS3", "DS4", "DS5")
all.time2 = gather(all.time, Dataset, Time, DS1:DS2)
all.time2$Method = factor(all.time2$Method, levels=all.time$Method[order(myorder,decreasing=T)])
ggplot(all.time2, aes(x=Method)) + geom_point(aes(y=Time,col=Dataset)) +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))
```